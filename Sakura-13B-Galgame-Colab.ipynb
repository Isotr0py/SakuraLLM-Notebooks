{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Isotr0py/SakuraLLM-Notebooks/blob/main/Sakura-13B-Galgame-Colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tvkI52m5DRsL"
      },
      "outputs": [],
      "source": [
        "#@title 初始化环境\n",
        "#@markdown 挂载Google网盘\n",
        "Mount_GDrive = False # @param {type:\"boolean\"}\n",
        "if Mount_GDrive:\n",
        "  from google.colab import drive\n",
        "\n",
        "  drive.mount('/content/gdrive')\n",
        "  ROOT_PATH = \"/content/gdrive/MyDrive\"\n",
        "else:\n",
        "  ROOT_PATH = \"/content\"\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gelzXVWEGxZw"
      },
      "outputs": [],
      "source": [
        "#@title 安装依赖\n",
        "%cd $ROOT_PATH\n",
        "!git clone https://github.com/SakuraLLM/Sakura-13B-Galgame.git\n",
        "\n",
        "%cd Sakura-13B-Galgame\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -q pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DUQnJQ96Jau8"
      },
      "outputs": [],
      "source": [
        "#@title 翻译EPUB\n",
        "MODEL = \"SakuraLLM/Sakura-13B-LNovel-v0_8-4bit\" # @param [\"SakuraLLM/Sakura-13B-LNovel-v0_8-3bit\", \"SakuraLLM/Sakura-13B-LNovel-v0_8-4bit\", \"SakuraLLM/Sakura-13B-LNovel-v0_8-8bit\"]\n",
        "EPUB_PATH = \"novel.epub\" # @param {type:\"string\"}\n",
        "OUTPUT_FOLDER = \"output/\" # @param {type:\"string\"}\n",
        "\n",
        "%cd $ROOT_PATH/Sakura-13B-Galgame\n",
        "!python translate_epub.py \\\n",
        "    --model_name_or_path $MODEL \\\n",
        "    --trust_remote_code \\\n",
        "    --model_version 0.8 \\\n",
        "    --use_gptq_model \\\n",
        "    --text_length 512 \\\n",
        "    --data_path $EPUB_PATH \\\n",
        "    --output_folder $OUTPUT_FOLDER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "S9gYbA1yMVND"
      },
      "outputs": [],
      "source": [
        "#@title 翻译文本文件\n",
        "MODEL = \"SakuraLLM/Sakura-13B-LNovel-v0_8-4bit\" # @param [\"SakuraLLM/Sakura-13B-LNovel-v0_8-3bit\", \"SakuraLLM/Sakura-13B-LNovel-v0_8-4bit\", \"SakuraLLM/Sakura-13B-LNovel-v0_8-8bit\"]\n",
        "DATA_PATH = \"novel.txt\" # @param {type:\"string\"}\n",
        "OUTPUT_PATH = \"novel_translated.txt\" # @param {type:\"string\"}\n",
        "\n",
        "%cd $ROOT_PATH/Sakura-13B-Galgame\n",
        "!python translate_novel.py \\\n",
        "    --model_name_or_path $MODEL \\\n",
        "    --trust_remote_code \\\n",
        "    --model_version 0.8 \\\n",
        "    --use_gptq_model \\\n",
        "    --text_length 512 \\\n",
        "    --data_path $DATA_PATH \\\n",
        "    --output_path $OUTPUT_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wo7uQVKUABIY"
      },
      "outputs": [],
      "source": [
        "#@title 运行API后端\n",
        "#@markdown 使用[ngrok](https://ngrok.com/)进行API映射\n",
        "ngrokToken = \"\"  # @param {type:\"string\"}\n",
        "if ngrokToken:\n",
        "  from pyngrok import conf, ngrok\n",
        "  conf.get_default().auth_token = ngrokToken\n",
        "  conf.get_default().monitor_thread = False\n",
        "  ssh_tunnels = ngrok.get_tunnels(conf.get_default())\n",
        "  if len(ssh_tunnels) == 0:\n",
        "      ssh_tunnel = ngrok.connect(5000)\n",
        "      print('address：'+ssh_tunnel.public_url)\n",
        "  else:\n",
        "      print('address：'+ssh_tunnels[0].public_url)\n",
        "\n",
        "MODEL = \"SakuraLLM/Sakura-13B-LNovel-v0_8-4bit\" # @param [\"SakuraLLM/Sakura-13B-LNovel-v0_8-3bit\", \"SakuraLLM/Sakura-13B-LNovel-v0_8-4bit\", \"SakuraLLM/Sakura-13B-LNovel-v0_8-8bit\"]\n",
        "\n",
        "!python server.py \\\n",
        "  --model_name_or_path $MODEL \\\n",
        "  --use_gptq_model \\\n",
        "  --model_version 0.8 \\\n",
        "  --trust_remote_code \\\n",
        "  --no-auth"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
